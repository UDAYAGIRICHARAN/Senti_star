{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyvy5FMkMtC0"
      },
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('/content/nlpforme.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLI33XmSNCkE"
      },
      "source": [
        "data.drop(0,axis=0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWC0ABTJODpH"
      },
      "source": [
        "#f=data[\"1\"].str.split(\"/\",1)\n",
        "#data[\"Title\"]=df.str.get(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reUrEKRIOVru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "660e5986-72b4-4b5f-f54e-48f615c84eeb"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Averting the climate crisis</td>\n",
              "      <td>3523392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The best stats you've ever seen</td>\n",
              "      <td>14501685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simplicity sells</td>\n",
              "      <td>1920832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Greening the ghetto</td>\n",
              "      <td>2664069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Do schools kill creativity?</td>\n",
              "      <td>65051954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 1         6\n",
              "1      Averting the climate crisis   3523392\n",
              "2  The best stats you've ever seen  14501685\n",
              "3                 Simplicity sells   1920832\n",
              "4              Greening the ghetto   2664069\n",
              "5      Do schools kill creativity?  65051954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dCSWWg-Ul9m"
      },
      "source": [
        "#data[\"Title\"]=data.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Z5uKRgp5Ye"
      },
      "source": [
        "#data[\"1\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwHXcRiMT5aw"
      },
      "source": [
        "#data.to_csv(\"nlpfinal\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCNsgJNXYL1U"
      },
      "source": [
        "#data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io7fEvYmNXOc"
      },
      "source": [
        "## NLP START::::"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeMFZGGNUIzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e3da2dce-4d07-4a06-877f-08afec44559c"
      },
      "source": [
        "! pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9rtmWTorFN5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "128a2609-5b68-41ac-b217-5c27ef24e25f"
      },
      "source": [
        "# Cleaning the texts\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(1, 4006):\n",
        "    \n",
        "    review = re.sub('[^a-zA-Z]', ' ', data['1'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "# Creating the TF-IDF model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv = TfidfVectorizer()\n",
        "X = cv.fit_transform(corpus).toarray()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr0ZuKqgM6BN"
      },
      "source": [
        "\n",
        "y = data[\"6\"].values\n",
        "\n",
        "\n",
        " #Training the Random Forest Regression model on the whole dataset\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "regressor.fit(X, y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hgpeo5PZcqQ"
      },
      "source": [
        "\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
        " #Training the Random Forest Regression model on the whole dataset\n",
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "#regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "#regressor.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhqBnJVDZh33"
      },
      "source": [
        "#from sklearn.metrics import mean_squared_error\n",
        "#mean_squared_error(y_test, y_pred)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSy6jBmFYz3k"
      },
      "source": [
        "''''from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)''''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcyAIyItYFPd"
      },
      "source": [
        "''''# Applying k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
        "\n",
        "# Applying Grid Search to find the best model and the best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
        "print(\"Best Parameters:\", best_parameters)\n",
        "'''''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUEA8ei8Nfep"
      },
      "source": [
        "new_review = \" The future we're building and boring | Elon Musk\"\n",
        "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
        "new_review = new_review.lower()\n",
        "new_review = new_review.split()\n",
        "ps = PorterStemmer()\n",
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
        "new_review = ' '.join(new_review)\n",
        "new_corpus = [new_review]\n",
        "new_X_test = cv.transform(new_corpus).toarray()\n",
        "new_y_pred = regressor.predict(new_X_test)\n",
        "print(new_y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}